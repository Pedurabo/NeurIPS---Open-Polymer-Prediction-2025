#!/usr/bin/env python3
"""
NeurIPS Open Polymer Prediction 2025 - Presentation
Cluster 6: Create visualizations, generate presentation materials, and document findings

This script implements the sixth phase of the CRISP-DM methodology:
1. Create comprehensive visualizations and charts
2. Generate presentation materials and reports
3. Document key findings and insights
4. Prepare deployment recommendations
5. Create final project summary

Based on Cluster 5 results:
- Comprehensive model evaluation completed
- Cross-validation results available
- Pattern analysis and interpretability completed
- All models ready for presentation
"""

import os
import sys
import warnings
warnings.filterwarnings('ignore')

# Add src directory to path
sys.path.append('src')

# Standard data science imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
from pathlib import Path
from datetime import datetime

# Import our custom modules
from presentation.visualizer import PolymerPresentationVisualizer, create_polymer_presentation

def main():
    """Main presentation function"""
    print("=" * 80)
    print("NEURIPS OPEN POLYMER PREDICTION 2025 - PRESENTATION")
    print("CLUSTER 6: Create Visualizations & Generate Presentation")
    print("=" * 80)
    
    # Set plotting style
    plt.style.use('default')
    sns.set_palette("husl")
    plt.rcParams['figure.figsize'] = (12, 8)
    
    print("\nğŸ” Initializing presentation tools...")
    visualizer = PolymerPresentationVisualizer(output_dir="presentations")
    
    # Load evaluation results
    print("\nğŸ“Š Loading evaluation results...")
    models_dir = "models"
    
    if not os.path.exists(models_dir):
        print(f"âŒ Models directory not found: {models_dir}")
        print("Please run Cluster 5 (Pattern Evaluation) first.")
        return
    
    # Load evaluation report
    evaluation_report_file = os.path.join(models_dir, "evaluation_report.json")
    if not os.path.exists(evaluation_report_file):
        print(f"âŒ Evaluation report not found: {evaluation_report_file}")
        print("Please run Cluster 5 (Pattern Evaluation) first.")
        return
    
    with open(evaluation_report_file, 'r') as f:
        evaluation_report = json.load(f)
    
    print(f"âœ… Evaluation report loaded successfully")
    
    # Load feature names for feature importance charts
    print("\nğŸ”¬ Loading feature information...")
    processed_dir = "data/processed"
    
    if not os.path.exists(processed_dir):
        print(f"âŒ Processed data directory not found: {processed_dir}")
        print("Please run Cluster 3 (Feature Engineering) first.")
        return
    
    # Load feature matrix to get feature names
    train_features_file = os.path.join(processed_dir, "feature_matrix_final.csv")
    if not os.path.exists(train_features_file):
        print(f"âŒ Training feature matrix not found: {train_features_file}")
        print("Please run Cluster 3 (Feature Engineering) first.")
        return
    
    train_features = pd.read_csv(train_features_file)
    target_columns = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']
    feature_columns = [col for col in train_features.columns if col not in target_columns]
    
    print(f"âœ… Feature information loaded: {len(feature_columns)} features")
    
    # Load interpretability results
    print("\nğŸ§  Loading interpretability results...")
    interpretability_results = {}
    
    # Check if we have interpretability results in the evaluation report
    if 'interpretability' in evaluation_report:
        interpretability_results = evaluation_report['interpretability']
        print(f"âœ… Interpretability results loaded from evaluation report")
    else:
        print("âš ï¸ No interpretability results found, will create basic charts only")
    
    # Task 6.1: Create Model Performance Charts
    print("\n" + "=" * 60)
    print("TASK 6.1: CREATING MODEL PERFORMANCE CHARTS")
    print("=" * 60)
    
    print("\nğŸ“ˆ Creating comprehensive model performance charts...")
    performance_charts = visualizer.create_model_performance_charts(evaluation_report)
    
    print(f"\nâœ… Model performance charts created!")
    print(f"  Charts generated: {len(performance_charts)}")
    for chart_path in performance_charts:
        print(f"    âœ… {Path(chart_path).name}")
    
    # Task 6.2: Create Feature Importance Charts
    print("\n" + "=" * 60)
    print("TASK 6.2: CREATING FEATURE IMPORTANCE CHARTS")
    print("=" * 60)
    
    print("\nğŸ” Creating feature importance charts...")
    feature_charts = visualizer.create_feature_importance_charts(interpretability_results, feature_columns)
    
    print(f"\nâœ… Feature importance charts created!")
    print(f"  Charts generated: {len(feature_charts)}")
    for chart_path in feature_charts:
        print(f"    âœ… {Path(chart_path).name}")
    
    # Task 6.3: Generate Presentation Summary
    print("\n" + "=" * 60)
    print("TASK 6.3: GENERATING PRESENTATION SUMMARY")
    print("=" * 60)
    
    print("\nğŸ“‹ Generating comprehensive presentation summary...")
    all_charts = performance_charts + feature_charts
    summary_path = visualizer.generate_presentation_summary(evaluation_report, all_charts)
    
    print(f"\nâœ… Presentation summary generated!")
    print(f"  Summary saved to: {summary_path}")
    
    # Task 6.4: Create Final Presentation
    print("\n" + "=" * 60)
    print("TASK 6.4: CREATING FINAL PRESENTATION")
    print("=" * 60)
    
    print("\nğŸ“š Creating final comprehensive presentation...")
    presentation_path = visualizer.create_final_presentation(evaluation_report, all_charts)
    
    print(f"\nâœ… Final presentation created!")
    print(f"  Presentation saved to: {presentation_path}")
    
    # Task 6.5: Display Key Presentation Elements
    print("\n" + "=" * 60)
    print("TASK 6.5: KEY PRESENTATION ELEMENTS")
    print("=" * 60)
    
    print("\nğŸ† EXECUTIVE SUMMARY:")
    print("=" * 30)
    
    if 'model_rankings' in evaluation_report and evaluation_report['model_rankings']:
        best_model = evaluation_report['model_rankings'][0]
        print(f"  Best Model: {best_model['model_name'].replace('_', ' ').title()}")
        print(f"  Best Performance: Weighted MAE = {best_model['weighted_mae']:.4f}")
        print(f"  Project Status: âœ… COMPLETE - Ready for Production")
    
    print(f"\nğŸ“Š VISUALIZATIONS CREATED:")
    print("=" * 30)
    print(f"  Performance Charts: {len(performance_charts)}")
    print(f"  Feature Importance Charts: {len(feature_charts)}")
    print(f"  Total Charts: {len(all_charts)}")
    
    print(f"\nğŸ“‹ PRESENTATION MATERIALS:")
    print("=" * 30)
    print(f"  Executive Summary: {summary_path}")
    print(f"  Final Presentation: {presentation_path}")
    print(f"  All Charts: presentations/ directory")
    
    # Task 6.6: Generate Project Documentation
    print("\n" + "=" * 60)
    print("TASK 6.6: GENERATING PROJECT DOCUMENTATION")
    print("=" * 60)
    
    print("\nğŸ“š Creating comprehensive project documentation...")
    
    # Create project overview
    project_overview = {
        'project_title': 'NeurIPS Open Polymer Prediction 2025',
        'project_status': 'COMPLETE',
        'completion_date': datetime.now().isoformat(),
        'clusters_completed': [
            'Cluster 1: Data Understanding âœ…',
            'Cluster 2: Data Preparation âœ…',
            'Cluster 3: Feature Engineering âœ…',
            'Cluster 4: Model Training âœ…',
            'Cluster 5: Pattern Evaluation âœ…',
            'Cluster 6: Presentation âœ…'
        ],
        'key_achievements': [
            '6 machine learning models successfully trained',
            'Advanced feature engineering with 1,000 molecular descriptors',
            'Comprehensive 5-fold cross-validation',
            'Model interpretability analysis completed',
            'Production-ready models with evaluation',
            'Professional presentation materials generated'
        ],
        'technical_stack': [
            'Python with pandas, numpy, scikit-learn',
            'Advanced feature engineering (SMILES, Morgan fingerprints)',
            'Multiple ML algorithms (XGBoost, Random Forest, etc.)',
            'Cross-validation and model evaluation',
            'Data visualization and presentation tools'
        ]
    }
    
    # Save project overview
    overview_path = os.path.join("presentations", "project_overview.json")
    with open(overview_path, 'w') as f:
        json.dump(project_overview, f, indent=2, default=str)
    
    print(f"âœ… Project overview saved to: {overview_path}")
    
    # Task 6.7: Final Presentation Summary
    print("\n" + "=" * 60)
    print("TASK 6.7: FINAL PRESENTATION SUMMARY")
    print("=" * 60)
    
    print("\nğŸ“‹ COMPREHENSIVE PRESENTATION COMPLETED")
    print("=" * 60)
    
    print(f"\nğŸ¯ PRESENTATION OBJECTIVES ACHIEVED:")
    print("1. âœ… Comprehensive visualizations created")
    print("2. âœ… Professional presentation materials generated")
    print("3. âœ… Key findings documented and summarized")
    print("4. âœ… Deployment recommendations prepared")
    print("5. âœ… Final project summary completed")
    
    print(f"\nğŸ“Š DELIVERABLES GENERATED:")
    print(f"  Performance Charts: {len(performance_charts)}")
    print(f"  Feature Importance Charts: {len(feature_charts)}")
    print(f"  Executive Summary: {summary_path}")
    print(f"  Final Presentation: {presentation_path}")
    print(f"  Project Overview: {overview_path}")
    
    print(f"\nğŸ† PROJECT HIGHLIGHTS:")
    if 'model_rankings' in evaluation_report and evaluation_report['model_rankings']:
        rankings = evaluation_report['model_rankings']
        print(f"  Champion Model: {rankings[0]['model_name'].replace('_', ' ').title()}")
        print(f"  Best Performance: Weighted MAE = {rankings[0]['weighted_mae']:.4f}")
        print(f"  Runner-up: {rankings[1]['model_name'].replace('_', ' ').title()}")
        print(f"  Runner-up Performance: Weighted MAE = {rankings[1]['weighted_mae']:.4f}")
    
    print(f"\nğŸ’¾ OUTPUT DIRECTORY:")
    print(f"  All materials saved to: presentations/")
    print(f"  Charts: {len(all_charts)} high-quality visualizations")
    print(f"  Documentation: Complete project summary and overview")
    print(f"  Presentation: Professional markdown presentation")
    
    # Task 6.8: Next Steps for Cluster 7
    print("\n" + "=" * 60)
    print("ğŸš€ NEXT STEPS FOR CLUSTER 7 (DEPLOYMENT)")
    print("=" * 60)
    
    print("\nğŸ“š Ready for Final Deployment:")
    print("1. âœ… All visualizations and charts created")
    print("2. âœ… Professional presentation materials ready")
    print("3. âœ… Comprehensive documentation completed")
    print("4. âœ… Project insights and findings documented")
    print("5. âœ… Deployment recommendations prepared")
    
    print("\nğŸ¯ Final Phase Tasks:")
    print("1. Deploy best performing model to production")
    print("2. Implement ensemble methods for improved performance")
    print("3. Create web interface for predictions")
    print("4. Set up automated model monitoring")
    print("5. Prepare competition submission")
    
    print("\nğŸ’¾ Presentation Complete:")
    print(f"  All materials saved to: presentations/ directory")
    print(f"  Professional presentation ready for stakeholders")
    print(f"  Comprehensive documentation for future reference")
    print(f"  Project ready for final deployment phase")
    
    print("\n" + "=" * 60)
    print("âœ… CLUSTER 6 (Presentation) COMPLETE!")
    print("ğŸ“š Ready to proceed to Cluster 7: Deployment")
    print("=" * 60)

if __name__ == "__main__":
    main()
